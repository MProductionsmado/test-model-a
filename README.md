# ğŸ° Minecraft KI - Text zu Struktur Generator

**Generiere Minecraft-Strukturen aus Text-Beschreibungen mit KI!**

<div align="center">

```
"a big medieval house with oak wood and stone base"
                    â†“
         [KI verarbeitet...]
                    â†“
        16Ã—16Ã—16 .schem Datei
```

</div>

---

## ğŸ¯ Was ist das?

Eine **Conditional GPT-basierte KI**, die Minecraft-Strukturen (16Ã—16Ã—16) aus Text-Prompts generiert.

**Trainiert auf:** 2415 Minecraft-Strukturen mit Beschreibungen  
**Technologie:** PyTorch, Transformer (GPT), Cross-Attention  
**Output:** `.schem` Dateien (fÃ¼r WorldEdit/MCEdit)

---

## âš¡ Quick Start

```powershell
# 1. Installation
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt

# 2. Training starten (automatisch optimiert!)
python src/conditional_train.py --data_path data/train --val_path data/val --batch_size 48 --epochs 100

# 3. Strukturen generieren
python src/conditional_generate.py --prompt "a big medieval house" --checkpoint checkpoints/conditional_model_best.pt
```

**Performance (H100 80GB mit automatischem Caching):**
- âš¡ **10-15 it/s** (automatisch optimiert)
- ğŸš€ **100 Epochen in ~15-20 Minuten**
- ğŸ’¾ Alles wird beim Start in RAM gecacht (~500 MB)

**Fertig!** ğŸ‰ Strukturen sind in `generated/`

---

## ğŸ“š Dokumentation

### ğŸ“ [**TUTORIAL.md**](TUTORIAL.md) - FÃ¼r AnfÃ¤nger
- Schritt-fÃ¼r-Schritt Installation
- Training starten und Ã¼berwachen
- Strukturen generieren
- ProblemlÃ¶sung
- **â†’ START HIER wenn du loslegen willst!**

### ğŸ§  [**FUNKTIONSWEISE.md**](FUNKTIONSWEISE.md) - Technische Details
- Wie die KI funktioniert
- Transformer-Architektur
- Text-Encoder & Cross-Attention
- Training-Prozess
- Mathematische Grundlagen
- **â†’ FÃ¼r technisch Interessierte**

---

## ğŸ¨ Beispiel-Prompts

```
"a big medieval house with oak wood and stone base with red pointed roof"
"an abandoned barn built out of spruce wood with interior"
"a small church with wooden roof and stone foundation"
"a fantasy tower with multiple floors and stone walls"
"an arabic desert house out of sandstone without interior"
```

**Tipp:** Die KI kennt 202 WÃ¶rter aus den Trainings-Daten. Verwende Ã¤hnliche Beschreibungen fÃ¼r beste Ergebnisse!

---

## ğŸ“ Projekt-Struktur

```
model a gpt/
â”œâ”€â”€ ğŸ“– TUTORIAL.md                    # Anleitung fÃ¼r Benutzer
â”œâ”€â”€ ğŸ“– FUNKTIONSWEISE.md              # Technische Dokumentation
â”œâ”€â”€ ğŸš€ quickstart_conditional.py      # Automatisches Setup & Training
â”œâ”€â”€ âš™ï¸ config.yaml                    # Konfiguration
â”œâ”€â”€ ğŸ“¦ requirements.txt               # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ ğŸ—‚ï¸ text_vocab.json                # Text-Vokabular (202 WÃ¶rter)
â”‚
â”œâ”€â”€ src/                              # Source Code
â”‚   â”œâ”€â”€ conditional_model.py          # KI-Modell (Conditional GPT)
â”‚   â”œâ”€â”€ conditional_dataset.py        # Dataset-Loader
â”‚   â”œâ”€â”€ conditional_train.py          # Training-Script
â”‚   â”œâ”€â”€ conditional_generate.py       # Generierungs-Script
â”‚   â”œâ”€â”€ text_tokenizer.py             # Text-Verarbeitung
â”‚   â”œâ”€â”€ vocab.py                      # Block-Vokabular (121 BlÃ¶cke)
â”‚   â”œâ”€â”€ schematic_parser.py           # .schem Datei-Parser
â”‚   â”œâ”€â”€ prepare_dataset.py            # Dataset-Aufteilung
â”‚   â””â”€â”€ utils.py                      # Hilfsfunktionen
â”‚
â””â”€â”€ fixed_all_files (1)/              # Training-Daten
    â””â”€â”€ fixed_all_files/              # 2415 .schem Dateien
```

---

## ğŸ”§ Features

âœ… **Text-zu-Struktur-Generierung** mit GPT-Architektur  
âœ… **Cross-Attention** zwischen Text und Struktur  
âœ… **121 Minecraft-BlÃ¶cke** aus 5 Kategorien  
âœ… **Autoregressive Generierung** (Block-fÃ¼r-Block)  
âœ… **Multiple Variationen** pro Prompt mÃ¶glich  
âœ… **Temperature/Top-k/Top-p Sampling** fÃ¼r KreativitÃ¤ts-Kontrolle  
âœ… **TensorBoard Integration** fÃ¼r Training-Monitoring  
âœ… **Checkpoint-System** (Best/Final/Epochen)  
âœ… **GPU & CPU Support** (GPU empfohlen)  

---

## ğŸ“Š Technische Specs

| Komponente | Details |
|------------|---------|
| **Architektur** | Conditional Transformer GPT |
| **Parameter** | ~50-60 Millionen |
| **Text-Encoder** | 4-Layer Transformer, 256-dim |
| **Main Model** | 12-Layer, 512-dim, 8-heads |
| **Text-Vokabular** | 202 WÃ¶rter |
| **Block-Vokabular** | 121 Minecraft-BlÃ¶cke |
| **Struktur-GrÃ¶ÃŸe** | 16Ã—16Ã—16 (4096 BlÃ¶cke) |
| **Training-Daten** | 2415 annotierte .schem Dateien |
| **Framework** | PyTorch 2.0+ |

---

## âš¡ Performance

| Aufgabe | GPU (RTX 3060) | CPU |
|---------|----------------|-----|
| **Training** (1 Epoche) | ~30 Sekunden | ~5-10 Minuten |
| **Generierung** (1 Struktur) | ~20-40 Sekunden | ~2-5 Minuten |
| **Gesamt-Training** (100 Epochen) | ~50 Minuten | ~8-16 Stunden |

---

## ğŸ“ Erste Schritte

### 1ï¸âƒ£ FÃ¼r Einsteiger
ğŸ‘‰ **Lies [TUTORIAL.md](TUTORIAL.md)**
- Installation
- Training starten
- Erste Struktur generieren

### 2ï¸âƒ£ FÃ¼r Entwickler
ğŸ‘‰ **Lies [FUNKTIONSWEISE.md](FUNKTIONSWEISE.md)**
- Architektur verstehen
- Code-Struktur
- Eigene Anpassungen

### 3ï¸âƒ£ FÃ¼r Schnellstarter
ğŸ‘‰ **FÃ¼hre aus:**
```powershell
python quickstart_conditional.py --test_mode
```
(5 Epochen Test-Training)

---

## ğŸ› Probleme?

**"CUDA out of memory"**
```powershell
python src/conditional_train.py --batch_size 8
```

**"ModuleNotFoundError: torch"**
```powershell
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**Training zu langsam?**
- GPU verwenden (10-100x schneller)
- Kleinere Batch-Size
- Weniger Epochen im Test-Modus

â¡ï¸ **Mehr in [TUTORIAL.md](TUTORIAL.md) â†’ ProblemlÃ¶sung**

---

## ğŸ“¦ Requirements

```
Python 3.8+
torch >= 2.0.0
mcschematic >= 1.0.0
numpy
pyyaml
tqdm
tensorboard
```

Installation: `pip install -r requirements.txt`

---

## ğŸ® Strukturen in Minecraft nutzen

### WorldEdit (Empfohlen)
1. Kopiere `.schem` nach `.minecraft/config/worldedit/schematics/`
2. In Minecraft: `//schem load <name>` â†’ `//paste`

### MCEdit / Amulet Editor
1. Ã–ffne Welt im Editor
2. Import â†’ Schematic
3. Platzieren

---

## ğŸ’¡ Tipps

1. **Trainiere lÃ¤nger:** 50-100 Epochen fÃ¼r beste QualitÃ¤t
2. **Nutze Trainings-Vokabular:** WÃ¶rter wie "medieval", "oak", "interior" funktionieren gut
3. **Experimentiere mit Temperature:** 0.7 (sicher) bis 1.3 (kreativ)
4. **Generiere mehrere Variationen:** `--num_samples 5`
5. **Ãœberwache mit TensorBoard:** `tensorboard --logdir=runs`

---

## ğŸš€ NÃ¤chste Schritte

```powershell
# Starte jetzt!
python quickstart_conditional.py --test_mode

# Ã–ffne TensorBoard
tensorboard --logdir=runs

# Generiere nach Training
python src/conditional_generate.py \
    --prompt "a medieval house with oak wood" \
    --checkpoint checkpoints/conditional_model_best.pt \
    --num_samples 3
```

---

## ğŸ“„ Lizenz

Dieses Projekt ist fÃ¼r Bildungs- und persÃ¶nliche Zwecke gedacht.

---

## ğŸ™ Credits

- **mcschematic** - Minecraft Schematic Library
- **PyTorch** - Deep Learning Framework
- **Transformer Architecture** - Vaswani et al. "Attention is All You Need"

---

<div align="center">

**Viel Erfolg mit deinem Minecraft-KI-Projekt!** ğŸ°âœ¨

[Tutorial](TUTORIAL.md) â€¢ [Funktionsweise](FUNKTIONSWEISE.md) â€¢ [Config](config.yaml)

</div>
